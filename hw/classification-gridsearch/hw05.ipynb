{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset & processes it:\n",
    "# - fills NA data\n",
    "# - processes categorical data so that categories from both train&test are known\n",
    "def load_dataset(dataset, drop_columns=None):\n",
    "    df_train = pd.read_csv(\"./2019-npfl104-shared/data/\"+dataset+\"/train.txt.gz\", header=None)\n",
    "    df_test = pd.read_csv(\"./2019-npfl104-shared/data/\"+dataset+\"/test.txt.gz\", header=None)\n",
    "\n",
    "    train_size = len(df_train)\n",
    "    df_tog = df_train.append(df_test)\n",
    "\n",
    "    # Convert to categorical\n",
    "    for col in df_tog.columns[np.where(df_tog.dtypes == 'object')]:\n",
    "        df_tog[col] = pd.Categorical(df_tog[col])\n",
    "\n",
    "    # Drop too unique columns e.g. ids\n",
    "    for col in df_tog.columns:\n",
    "        idlike_col = []\n",
    "        if df_tog[col].nunique() > 0.6 * len(df_tog):\n",
    "            idlike_col.append(col)\n",
    "    df_tog = df_tog.drop(idlike_col, axis=1)\n",
    "        \n",
    "    # Explicitely drop specified columns\n",
    "    if drop_columns:\n",
    "        df_tog = df_tog.drop(drop_columns, axis=1)\n",
    "\n",
    "    df_train, df_test = df_tog[:train_size], df_tog[train_size:]\n",
    "    \n",
    "    df_train = df_train.fillna(df_train.mode().iloc[0])\n",
    "    df_test = df_test.fillna(df_test.mode().iloc[0])\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Used to split dataframe to features & target (last column)\n",
    "def get_X(df):\n",
    "    return pd.get_dummies(df[df.columns[:-1]], dummy_na=True)\n",
    "def get_Y(df):\n",
    "    dfc = df[df.columns[-1]]\n",
    "    return dfc.cat.codes if dfc.dtype.name == \"category\" else dfc\n",
    "\n",
    "\n",
    "dftr, dfte = load_dataset(\"pamap-easy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (SVC(kernel=\"linear\", C=1, gamma='scale'), \"SVC\", \"l\"),\n",
    "    (SVC(kernel=\"poly\", C=1, gamma='scale'), \"SVC\", \"p\"),\n",
    "    (SVC(kernel=\"rbf\", C=1, gamma='scale'), \"SVC\", \"p\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93932695 0.94103194 0.94810625 0.94609894 0.93868505]\n",
      "[0.93146647 0.93857494 0.944909   0.94806793 0.9411475 ]\n",
      "[0.88970769 0.87813268 0.8792425  0.88038395 0.88278749]\n"
     ]
    }
   ],
   "source": [
    "for cls in classifiers:\n",
    "    model, cls_name, cls_args = cls\n",
    "        \n",
    "    score = cross_val_score(model, get_X(dftr), get_Y(dftr), cv=5)  \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'kernel':['rbf'], \n",
    "    'C':[0.1, 1, 10, 100, 1000], \n",
    "    'gamma': [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-2,\n",
       "       param_grid={'kernel': ['rbf'], 'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(gamma='scale')\n",
    "gs = GridSearchCV(model, parameters, cv=3, n_jobs=-2, return_train_score=True)\n",
    "\n",
    "res = gs.fit(get_X(dftr), get_Y(dftr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
